# Note:
# this is the config file for launchcontainers.py 
# this file should be stored under the dir: ~/PROJECT/nifti with another file: subSES.txt 
# 
#
# Structure:
# three dictionary: config, container_options, and host_options

# in the config dict, it provides info about the directory where data, code, template, container, and logs were stored, 
# also, it provides info about the container, host, qsub we use. 
config:
  # Base folder of your project where the dicom and nifti folder are. 
  # Give the full path starting from /, do not use ~
  # If you are using public folders, go from generic public wihout using your path
  basedir: /export/home/llecca/public/LEPA/testlaunchcontainers
  # I think that in the new version we will not need it, otherwise create a function that obtains it
  codedir: /export/home/llecca/llecca/soft/launchcontainersdev
  # Always necessary, it creates output and error logs per every subject and analysis   
  # It gets really big. Store somewhere in the cluster.
  # TODO: when it finishes succesfuly, store the log in the output folder of each subject
  logdir: /export/home/llecca/public/LEPA/testlaunchcontainers/logdir
  # This is cluster specific. the problem is that tmp files can be huge and fill your quota, 
  # so in most clusters they will give you a tmp folder that it will be deleted after every run 
  # and do not count through your total quota. In DIPC thi is very important
  tmpdir: /export/home/llecca/public/LEPA/testlaunchcontainers
  # Path to where all the singularity images are. For Docker, this can be empty
  containerdir: /bcbl/home/public/LEPA/containers
  # The container where it will be run, version and other details will be stored in container_options
  container: "rtp-pipeline"  # VALID OPTIONS: anatrois, rtppreproc, rtp-pipeline, TODO: heudiconv, prfprepare, prfanalyze, prfresults, fmriprep
  # Give a number or name to your analysis
  analysis: "03"
  # TODO: If the analysis exists, and force is true, then overwrite, otherwise stop
  # This force command applies to symlinks and analyses, if it set to true, it will always overwrite everything
  # FOR CREATESYMLINKS
  # if file_exists and force: overwrite
  # if file_exists and not force: do nothing and print(say that the file existed but you kept it)
  # if not file_exists: we don't care about force, you add the file (the symlink)
  # FOR CONTAINER_VERSION_ANALYSIS
  # IF CONTAINER_VERSION_ANALYSIS_EXISTS and force: print warning and overwirte
  force: false
  # The host where this will be run, see below for options  
  host: BCBL
  # If true it will use sge or slumr, otherwise it just generates the "docker" or "singularity" commands
  # Good for testing, just launch for one subject, for example
  qsub: true
  # Set this to true to just show the text of what it is going to launch
  # If this is set to true, it will not launch anything, it will only throw the text with the commands that will be launch
  # For testing only
  # TODO: implement this option
  # note for tiger: in the sh you did for heudiconv, this would be as
  # echo $CMD
  # if text_only=false: eval $CMD
  # cmd="do this and this"
  # print(cmd)
  # if not text_only: subprocess.run(cmd,shell=True)
  text_only: true

container_options:
# Add the containers and options you want to run
  fmriprep:
    version: 
    space: ""
  anatrois:
    version: 4.2.7-7.1.1
    # If you have run FS previously, you can say true here and it will use the existing output
    pre_fs: false
    # If pre_fs is true, it will try to find it using the options below
    # Add the container name and versions used to create the pre_fs
    precontainerfs: anatrois_4.2.7-7.1.1
    # There can be more than one analysis, give the number of the analysis here
    preanalysisfs: "re-0316-wall-15h"
    # It will find a zip file in the anatrois output, that starts with this string
    prefs_zipname: "anatrois"
    # These are optional input files. If there is none, leave it empty string
    # If it is empty, it will ignore it and will not create the input/folder
    annotfile: ""
    mniroizip: ""
  rtppreproc:
    version: 1.1.3
    # It checks if there is a reverse phase encoding acquisition
    # Old dcm2nixx will not create empty bvec and bval files if there was an acquisition with just b0-s
    # This code will create them automatically if they are not there
    # TODO: make it a function
    rpe: false
    # Find where the input files are. It will take the T1 and the brainmask from here
    #
    #this thing was pretoolfs originally
    precontainerfs: anatrois_4.2.7-7.1.1
    preanalysisfs: "01"
  rtp-pipeline:
    version: 4.4.1
    # Find where the input files are. It will take the T1 and the brainmask from here        
    precontainerfs: anatrois_4.2.7-7.1.1
    preanalysisfs: "01"
    precontainerpp: rtppreproc_1.1.3
    preanalysispp: "01"
    # Porject level tractparams or individual tractparams can be used. 
    # If it is poject level, there should be one tractparams in the analysis-xx folder, and it will crate a symlink in every subjects input folder
    # and if the file is not there, it will throw an error. 
    # If the option is seet to false, then the program will need to check that the tractparams file is in the inptu fodler per every subject, otherwise it will fail
    # TODO: the checking system is not implemented, the createSymLink it is
    one_tractparams_per_analysis: true
  prfprepare:
    version: 
  prfanalyze:
    version: 

host_options:
    # Default BCBL
    BCBL:
      sin_ver: singularity/3.5.2
      maxwall: 10
      manager: sge
      name: "anatrois"
      # Dask worker options
      cores: 6                    # Total number of cores per job (it was core for BCBL)
      memory: 32G                # Total amount of memory per job (it was mem for BCBL)
      processes: 1                # Number of Python processes per job

      interface: lo             # Network interface to use like eth0 or ib0
      death-timeout: 100           # Number of seconds to wait if a worker can not find a scheduler
      local-directory: null       # Location of fast local storage like /scratch or $TMPDIR

      # SGE resource manager options
      #shebang: "#!/usr/bin/env bash"
      queue: long.q              # It was que in BCBL
      project: null
      walltime: 25:30:00'
      extra: []
      env-extra: []
      job-extra: []
      logdir: /export/home/llecca/public/LEPA/testlaunchcontainers/logdir
      resource-spec: null


    # Defaul DIPC
    DIPC:
      mem: 8G
      que: regular
      core: 24
      sin_ver: Singularity/3.5.3-GCC-8.3.0
      manager: slurm
      system: lscratch
      maxwall: 24
    # Other
