########################
# This yaml file is to config launchcontainer, by inputing the correct infomation, you will be able to launch the corresponding container on your local or cluster
#
# This file should be copied from garikoitz/launchcontainer/example_configs 
# You may want to put it to your working directory ~/PROJECT/nifti
# It will work with a subsesList.txt file and other container specific config files

########################
########################
# General description:
# There are three categories of config information for you to set up this soft: 
# general settings, 
# container specific settings, 
# and computing host settings(we call it host options).

########################
########################
# Detailed explanations are explained under each dictionary.

########################
general:

  # basedir:  
      # type: str
      # description: Path to the folder of your project where you put the dicom and nifti folders. 
      # author note: 
      #   1. Remember to give the full path of the directory starting from /, do not use ~
      #   2. If you are using public folders, go from generic public wihout using your path e.g. useing /bcbl/public instead of using /export/xxxx/public
  # containerdir:
      # type: str
      # description: Path to where all the singularity images are stored. For Docker, this can be empty 
  # container:
      # type: str
      # description: Name of the container you want to launch, version and other details will needs to be input in container_options
      # auther note: 
      #   1. the valid options are listed below, be sure not to input wrong name
  # analysis:
      # type: str or int
      # description: The name of your analysis, e.g. 01, 001, abcd, etc. It will help you create a corresponding folder under derivetives/container
  # force:
      # type: bool / don't sensitive to capital letters True and true both okay
      # description: Options whether you want to overwritte the existing file or not
      # author note: 
      #   1.This force command applies to symlinks and analyses, if it set to true, it will always overwrite everything
      #   2.For PREPARE MODE
      #     if file_exists and force: overwrite
      #     if file_exists and not force: do nothing and print(say that the file existed but you kept it)
      #     if not file_exists: we don't care about force, you add the file (the symlink)
  # host
      # type: str
      # description: where you want to run the program, valid options: local, BCBL, DIPC.
       
  
  basedir: /export/home/tlei/tlei/PROJDATA/TESTDATA_LC/Testing_02
  sif_path: /bcbl/home/public/Gari/singularity_images
  container: prfprepare  # VALID OPTIONS: anatrois, rtppreproc, rtp-pipeline, prfprepare, prfanalyze-vista, prfresult, fmriprep TODO: heudiconv, 
  force: false
  analysis_name: '' # you can put a str here to give a brief description of your analysis, it will be called anaysis-{yourinput}-{number count} under derivative folder
  host: local #valid options: local, BCBL, DIPC.
  print_command_only: false  
  
container_specific:
# Add the containers and options you want to run
  fmriprep:
    version: 23.1.3 
    nthreads: 10
    mem: 20 #gb
    fs_license: /bcbl/home/public/Gari/VOTCLOC/license
    config_name: config
  anatrois:
    version: 4.5.2-7.3.2
    # If you have run FS previously, you can say true here and it will use the existing output
    pre_fs: false
    # If pre_fs is true, it will try to find it using the options below
    # Add the container name and versions used to create the pre_fs
    precontainer_anat: anatrois_4.5.2-7.3.2
    # There can be more than one analysis, give the number of the analysis here
    anat_analysis_num: "01"
    # It will find a zip file in the anatrois output, that starts with this string
    prefs_zipname: "anatrois"
    # These are optional input files. If there is none, leave it empty string
    # If it is empty, it will ignore it and will not create the input/folder
    annotfile: ""
    mniroizip: ""
    config_name: config
  rtppreproc:
    version: 1.2.0-3.0.3
    # It checks if there is a reverse phase encoding acquisition
    # Old dcm2nixx will not create empty bvec and bval files if there was an acquisition with just b0-s
    # This code will create them automatically if they are not there
    # TODO: make it a function
    rpe: ture
    # Find where the input files are. It will take the T1 and the brain mask from here
    #
    #this thing was pretoolfs originally
    precontainer_anat: anatrois_4.5.2-7.3.2
    anat_analysis_num: "01"
    config_name: config
  rtp-pipeline:
    version: 4.4.1
    # Find where the input files are. It will take the T1 and the brain mask from here        
    precontainer_anat: anatrois_4.2.7-7.1.1
    anat_analysis_num: "01"
    precontainer_preproc: rtppreproc_1.2.0-3.0.3
    preproc_analysis_num: "01"
    # Porject level tractparams or individual tractparams can be used. 
    # If it is poject level, there should be one tractparams in the analysis-xx folder, and it will crate a symlink in every subjects input folder
    # and if the file is not there, it will throw an error. 
    # If the option is seet to false, then the program will need to check that the tractparams file is in the inptu fodler per every subject, otherwise it will fail
    # TODO: the checking system is not implemented, the createSymLink it is
    one_tractparams_per_analysis: true
    config_name: config
  prfprepare:
    version: 1.4.0
    config_name: prfprepare 
  prfanalyze-vista:
    version: 2.2.1
    config_name: prfanalyze-vista
  prfresult:
    version: 0.0.6
    config_name: prfresult
host_options:
    # config BCBL
    BCBL:
      sin_ver: singularity/3.5.2
      maxwall: 10
      manager: sge
      name: "anatrois"
      # Dask worker options
      cores: 6                    # Total number of cores per job (it was core for BCBL)
      memory: 32G                # Total amount of memory per job (it was mem for BCBL)
      processes: 1                # Number of Python processes per job

      interface: lo             # Network interface to use like eth0 or ib0
      death-timeout: 100           # Number of seconds to wait if a worker can not find a scheduler
      local-directory: null       # Location of fast local storage like /scratch or $TMPDIR

      # SGE resource manager options
      #shebang: "#!/usr/bin/env bash"
      queue: long.q              # It was que in BCBL
      project: null
      walltime: 25:30:00'
      extra: []
      env-extra: []
      job-extra: []
      logdir: /export/home/tlei/tlei/PROJDATA/TESTDATA_LC/Testing_02/BIDS/dask_log
      resource-spec: null


    # config DIPC
    DIPC:
      memory: 32G
      queue: regular
      cores: 24
      walltime: '22:00:00'
      sin_ver: Singularity/3.5.3-GCC-8.3.0
      manager: slurm
      system: scratch
      name: "anatrois"
    # maxwall: 5
      logdir: /scratch/tlei/devtrajtract/DATA/BERTSOLARI/logdir
      tmpdir: /scratch/tlei/tmp
   
    local:
      manager: local
      threads_per_worker: 3
      processes: False
      memory_limit: '2GB' # memory limit for each worker
